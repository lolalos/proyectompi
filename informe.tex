\documentclass[fleqn,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{amsmath,amssymb}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{tcolorbox}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{hyperref}
\usepackage{verbatim}
\usepackage[spanish]{babel}
\usepackage{csquotes}
\usepackage{lipsum}

\geometry{a4paper, margin=1in}

% Estilo para código Python y C++
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{cppstyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    tabsize=2,
    language=C++,
    showstringspaces=false,
    numbers=left,
    numbersep=5pt,
    frame=single,
    rulecolor=\color{black}
}

\lstset{style=cppstyle}

\begin{document}

%---------------------- portada ----------------------
\begin{titlepage}
    \centering
    \vspace*{1cm}
    {\LARGE\bfseries UNIVERSIDAD NACIONAL DE SAN ANTONIO ABAD DEL CUSCO\par}
    \vspace{0.5cm}
    {\Large FACULTAD DE INGENIERÍA ELÉCTRICA, ELECTRÓNICA, INFORMÁTICA Y MECÁNICA\par}
    \vspace{0.5cm}
    {\Large ESCUELA PROFESIONAL DE INGENIERÍA INFORMÁTICA Y DE SISTEMAS\par}
    \vfill
    \includegraphics[width=0.25\linewidth]{Escudo_UNSAAC.png}\par
    \vfill
    {\Large\bfseries CURSO: Algoritmos Paralelos y Distribuidos\par}
    \vspace{0.3cm}
    {\Large\bfseries Proyecto: Implementación de proyecto con MPI\par}
    \vspace{0.3cm}
    {\Large\bfseries PROFESOR: Dr. HANS HARLEY CCACYAHUILLCA BEJAR\par}
    \vspace{1cm}
    {\Large\bfseries ALUMNO: EFRAIN VITORINO MARÍN\par}
    {\Large\bfseries CÓDIGO: 160337\par}
    \vfill
    {\Large 2025-I\par}
\end{titlepage}

\setcounter{page}{1}
\pagestyle{plain}

\begin{center}
    \Large\bfseries RESUMEN
\end{center}
\vspace{0.5cm}

\noindent\textbf{Objetivo del Proyecto}\\
El propósito fundamental de PROYECTOMPI es resolver el problema del alto costo computacional de la segmentación de imágenes. El proyecto implementa una solución de computación paralela para distribuir la carga de trabajo entre múltiples núcleos de un procesador, reduciendo significativamente el tiempo total de procesamiento.

\vspace{0.5cm}
\noindent\textbf{Arquitectura y Tecnología}\\
La solución está desarrollada en C++ por su rendimiento y utiliza dos bibliotecas clave:

\begin{itemize}
    \item \textbf{OpenCV:} Para todas las operaciones relacionadas con el manejo de imágenes, como lectura, escritura y la aplicación del algoritmo de segmentación (pyrMeanShiftFiltering).
    
    \item \textbf{MPI (Message Passing Interface):} Para gestionar toda la comunicación y la paralelización. Permite que el programa se ejecute en múltiples procesos, dividiendo la tarea de manera efectiva.
\end{itemize}

El diseño se basa en una estrategia de paralelismo de datos, donde la imagen de entrada se divide en franjas horizontales (filas). Este enfoque es simple y muy eficaz para garantizar que cada proceso reciba una cantidad de trabajo casi idéntica, optimizando el uso de los recursos.

\vspace{0.5cm}
\noindent\textbf{Implementación y Evaluación}\\
El código principal (segment.cpp) no solo ejecuta la segmentación, sino que está diseñado como un marco de evaluación de rendimiento. Su característica más importante es la capacidad de medir y reportar automáticamente el tiempo de ejecución y el uso máximo de memoria para cada proceso.

Estas métricas se recolectan en el proceso principal usando MPI\_Gather, lo que permite un análisis detallado del rendimiento, la escalabilidad y el balance de carga de la solución. La ejecución en un entorno como WSL (Ubuntu en Windows) confirma la portabilidad del código, aunque las métricas de rendimiento en este entorno sirven principalmente para validar la lógica y no representan el potencial en un clúster de alto rendimiento.


\clearpage
\section{Introducción}
La segmentación de imágenes es un proceso fundamental y omnipresente en el campo de la visión por computador, con aplicaciones críticas que abarcan desde el diagnóstico médico y la bioinformática hasta los sistemas de conducción autónoma y el análisis de imágenes satelitales. Su objetivo es particionar una imagen digital en múltiples segmentos o regiones, con el fin de simplificar su representación y facilitar un análisis más profundo y significativo.

Sin embargo, la creciente demanda de imágenes de alta resolución y el uso de algoritmos cada vez más complejos han convertido a la segmentación en un significativo cuello de botella computacional. El procesamiento secuencial de estas tareas en un único núcleo de procesador es a menudo demasiado lento para aplicaciones prácticas, especialmente aquellas que requieren resultados en tiempo real.

Para superar este desafío, este proyecto explora y aplica los principios de la computación paralela. La estrategia central consiste en dividir la carga de trabajo de la segmentación y distribuirla entre un conjunto de procesos que se ejecutan simultáneamente. Para ello, se desarrolla una solución en C++ que utiliza el estándar Message Passing Interface (MPI) para orquestar la comunicación y la distribución de tareas, y la biblioteca OpenCV para las operaciones de procesamiento de imágenes. El objetivo final es diseñar, implementar y evaluar un sistema robusto y escalable capaz de acelerar drásticamente el proceso de segmentación, demostrando la viabilidad y el poder del paralelismo en la visión por computador moderna.

\clearpage
\section{Formulación del Problema}
El desafío fundamental de este proyecto surge de una tensión inherente en la visión por computador moderna: mientras la disponibilidad de datos visuales de alta resolución (imágenes 4K, gigapíxeles, etc.) ha crecido exponencialmente, las arquitecturas de software tradicionales, basadas en el procesamiento secuencial, no han escalado a la par. La segmentación de imágenes, un proceso cuya complejidad computacional a menudo crece de forma no lineal con el número de píxeles, se convierte en un cuello de botella crítico. Este no es un mero inconveniente técnico; es una barrera que impide el avance práctico en campos que dependen de análisis masivos de imágenes, como la genómica (análisis de tejido celular), la ciencia de materiales o los sistemas de monitoreo en tiempo real, donde una latencia elevada es inaceptable.

A raíz de esta brecha, la pregunta de investigación que guía este proyecto es la siguiente:
¿Cuáles son los principios de diseño y los compromisos de implementación necesarios para desarrollar una arquitectura de software paralelo que no solo reduzca drásticamente el tiempo de ejecución de algoritmos de segmentación computacionalmente intensivos, sino que también sea inherentemente escalable, portable y verificable en su rendimiento?

Responder a esta pregunta global exige la resolución de varios sub-problemas interconectados y de alta criticidad, donde el éxito del proyecto depende de la solución efectiva de cada uno:

\subsection{El Problema del Balance de Carga y la Ociosidad de Recursos}
Argumento: En un sistema paralelo, el tiempo total de ejecución está determinado por el proceso que tarda más en finalizar su tarea. Si la imagen se descompone de manera desigual, algunos núcleos de CPU terminarán su trabajo rápidamente y permanecerán inactivos, desperdiciando ciclos de cómputo valiosos. Por lo tanto, el problema no es simplemente "dividir la imagen", sino diseñar una estrategia de descomposición de datos que garantice una distribución de trabajo lo más equitativa posible. Esto debe hacerse, además, con un bajo costo computacional, ya que un algoritmo de particionamiento complejo podría anular las ganancias de tiempo que se buscan.

\subsection{El Problema de la Sobrecarga de Comunicación como Nuevo Cuello de Botella}
Argumento: Todo algoritmo paralelo es una combinación de cómputo y comunicación. Según la Ley de Amdahl, la aceleración potencial de un programa está limitada por su porción secuencial. En nuestro caso, la comunicación (la distribución inicial de datos y la recolección final de resultados) es una fase inherentemente secuencial o de sincronización. A medida que se añaden más procesos, el tiempo de cómputo por proceso disminuye, pero el volumen total de comunicación puede aumentar o la latencia de la red puede volverse dominante. El problema es, por tanto, diseñar un patrón de comunicación que minimice la latencia y la contención, para evitar que la comunicación misma se convierta en el nuevo cuello de botella que impida la escalabilidad.

\subsection{El Problema de la Medición Rigurosa y la Demostración de Escalabilidad}
Argumento: Una solución paralela no es exitosa simplemente porque "funciona más rápido". Su eficacia debe ser demostrada cuantitativamente. El problema aquí es definir un marco de evaluación riguroso. Esto implica seleccionar métricas clave, como la Aceleración (Speedup) y la Eficiencia, y establecer una metodología de pruebas que permita analizar cómo se comporta la solución a medida que se incrementan los recursos (núcleo de CPU). El objetivo final es demostrar que la arquitectura no solo ofrece una mejora en un caso específico, sino que escala de manera predecible, es decir, que al duplicar los recursos de cómputo, el tiempo de ejecución se reduce de manera casi proporcional, validando así la robustez del diseño paralelo.

\section{Antecedentes}
Para comprender el diseño y la implementación de nuestra solución, es crucial establecer las bases teóricas y tecnológicas sobre las cuales se construye el proyecto. Estos antecedentes abarcan el concepto de segmentación de imágenes, el funcionamiento detallado del algoritmo específico a paralelizar y el paradigma de computación paralela seleccionado.

\subsection{Segmentación de Imágenes}
La segmentación de imágenes es un proceso fundamental en la visión por computador que consiste en particionar una imagen digital en múltiples conjuntos de píxeles, conocidos como segmentos o regiones. El objetivo es transformar la representación de la imagen en algo más significativo y fácil de analizar. Esta división no es aleatoria; se basa en la agrupación de píxeles que comparten ciertas características, como la similitud en color, intensidad, textura o proximidad espacial. El resultado es una imagen simplificada donde se pueden identificar objetos, límites y otras estructuras de interés, sirviendo como un paso de preprocesamiento esencial para tareas más complejas como el reconocimiento de objetos, el análisis de escenas o la cuantificación de datos en imágenes médicas.

\subsection{Algoritmo Base: "Efficient Graph-Based Image Segmentation"}
El núcleo de este proyecto es la paralelización del algoritmo propuesto por Pedro Felzenszwalb y Daniel Huttenlocher. Este método es ampliamente reconocido por su eficiencia y la alta calidad de sus resultados, logrando un buen equilibrio entre la captura de detalles importantes y la eliminación de ruido. Su lógica se basa en la teoría de grafos.

\textbf{Representación como Grafo:} El algoritmo modela la imagen como un grafo no dirigido $G=(V,E)$, donde el conjunto de vértices $V$ corresponde a los píxeles de la imagen. El conjunto de aristas $E$ conecta pares de píxeles vecinos (normalmente en una vecindad de 8 píxeles). A cada arista se le asigna un peso $w(v_i, v_j)$ que representa la diferencia o disimilitud entre los píxeles $v_i$ y $v_j$ (por ejemplo, la distancia euclidiana en el espacio de color RGB).

\textbf{Predicado de Fusión:} La decisión de fusionar dos componentes (segmentos) se basa en un predicado que evalúa si la diferencia entre los componentes es pequeña en relación con la diferencia dentro de los mismos. Se define la diferencia interna de un componente $C$ como la arista de mayor peso dentro de su árbol de expansión mínima, $Int(C)=\max_{e \in MST(C,E)} w(e)$. Luego, se define la diferencia mínima interna entre dos componentes $C_1$ y $C_2$ como $MInt(C_1, C_2) = \min(Int(C_1)+\tau(C_1), Int(C_2)+\tau(C_2))$, donde $\tau(C)=k/|C|$ es un umbral que depende de un parámetro $k$ y del tamaño del componente. Dos componentes se fusionan si el peso de la arista que los conecta es menor o igual a esta diferencia mínima interna.

\textbf{Pasos del Algoritmo:}
\begin{enumerate}
    \item Se ordenan todas las aristas $E$ del grafo en orden no decreciente de su peso $w$.
    \item Se inicializa la segmentación con cada píxel siendo su propio componente.
    \item Se recorre la lista ordenada de aristas. Para cada arista, si los dos vértices que conecta pertenecen a componentes distintos y el predicado de fusión se cumple, dichos componentes se fusionan.
    \item El proceso termina después de haber considerado todas las aristas.
\end{enumerate}

Este enfoque greedy es eficaz porque al procesar las aristas de menor peso primero, se asegura que las fusiones se realicen sobre la base de las similitudes más fuertes, y el predicado adaptativo previene la fusión de componentes que son visiblemente distintos.

\subsection{Computación Paralela y el Estándar MPI}
Si bien el algoritmo de Felzenszwalb-Huttenlocher es eficiente en su ejecución secuencial, el procesamiento de imágenes de alta resolución (megapíxeles) aún puede demandar un tiempo considerable. La computación paralela ofrece la solución a este problema al dividir la carga de trabajo.

Para este proyecto, se ha elegido el modelo de memoria distribuida implementado a través del Message Passing Interface (MPI). MPI no es una biblioteca, sino una especificación estándar para la comunicación entre procesos que pueden estar ejecutándose en los núcleos de una misma máquina o en diferentes nodos de un clúster.

\textbf{Justificación de la elección:}
\begin{itemize}
    \item \textbf{Escalabilidad:} MPI está diseñado para escalar desde unos pocos procesos hasta miles, lo que lo hace ideal para abordar problemas de cualquier tamaño, limitados únicamente por el hardware disponible.
    \item \textbf{Portabilidad:} El código escrito con la API de MPI es altamente portable entre diferentes arquitecturas de hardware y sistemas operativos, garantizando que nuestra solución no esté atada a una plataforma específica.
    \item \textbf{Control Explícito:} MPI otorga al programador un control explícito sobre la comunicación, lo que permite diseñar y optimizar patrones de envío y recepción de datos (\texttt{MPI\_Send}, \texttt{MPI\_Recv}), así como operaciones colectivas (\texttt{MPI\_Bcast}, \texttt{MPI\_Gather}) que son fundamentales para la distribución inicial de la tarea y la recolección final de los resultados en nuestra solución diseñada.
\end{itemize}
